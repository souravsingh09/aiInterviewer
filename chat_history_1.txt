Interviewee: Hello
Interviewer: Hello Jobin Mathew, welcome! I'm Clarissa, and I'll be conducting your interview today. Please feel free to introduce yourself, including your total years of experience, current company, and any notable projects you've worked on.
Interviewee: I have a total of five years of experience with two of them as a Python developer. I'm presently working at Tech Mahindra. For the past two years, most of the projects I have worked on are machine learning and deep learning related, my most recent one being an attrition prediction project.
Interviewer: Can you tell me more about the attrition prediction project you worked on? What was your role in the project, and what were some of the key technologies and techniques you used?
Interviewee: So this acquisition prediction project was actually developed by another team, but the members of the team had actually exited, so it was transferred on to me and I had to manage that application from start to end. So basically I had to ensure that there was no issues that were coming up when the application was up and running and I had to ensure that all the outputs were getting properly corrected and everything like that.
Interviewer: So, it sounds like you were more of a maintenance and support role for the project, rather than the original developer. Can you walk me through some of the specific technologies and tools you used to manage and maintain the application? For example, were you using any specific CI/CD pipelines, or was it a manual process?
Interviewee: So it was more of a manual process. So in addition to the maintenance and support role for the project, I also had to improve the project. So the project was last developed around, I think around one year back, and I had to actually ensure that the model that we were using were up to date and all the proper technologies were being used, for example, for survey.
Interviewer: So, you were responsible for updating the models and ensuring that the project was using the latest technologies. Can you tell me more about the models you were working with? Were they supervised or unsupervised machine learning models, and what algorithms were used?
Interviewee: So we finally ended up using random forest algorithm because it was giving us much better responses or proper outputs when considering the metrics that we were using. So we were mostly using only supervised machine learning algorithms because we had the input file training and there was some expected outputs as well. So we use the supervised learning models to train it.
Interviewer: Okay. So you used a random forest algorithm, which is a type of supervised machine learning algorithm. Can you elaborate on what kind of metrics you were using to evaluate the performance of the model? Were you using any specific metrics such as accuracy, precision, recall, or F1 score?
Interviewee: So as you mentioned the four special specific metrics, we will utilize these four in order to evaluate the performance of the model. However, we focused more on a recall because in the attrition prediction project we actually had to decide or it was more important to identify those employees who had a higher chance of leaving the company. So recall was the more prominent metrics that we utilized.
Interviewer: Okay. So you used recall as the primary metric to evaluate the model's performance, as it was more important to identify employees who were likely to leave the company. Can you tell me more about how you handled imbalanced datasets in your project? Since recall is sensitive to class imbalance, how did you address this issue?
Interviewee: So in order to handle the imbalance data set we use this mode to make library which is present in Python And using this we oversample the minority class and under sample the majority class.
Interviewer: Okay. So you used the SMOTE (Synthetic Minority Over-sampling Technique) library in Python to oversample the minority class and undersample the majority class to handle the imbalanced dataset. Can you elaborate on how you used SMOTE specifically? For example, did you use any specific parameters or settings for SMOTE, such as the number of synthetic samples to generate?
Interviewee: So in this library we basically had to mention what should be the ratio of the oversampled or the sorry of the majority class and the minority class. So I made that both as 0.5 or that they should be equal.
Interviewer: Okay. So you set the ratio of the oversampled majority class to the minority class to 0.5, making both classes equal in terms of sample size. Can you tell me more about how you handled the data preprocessing step in your project? For example, did you perform any feature scaling, normalization, or encoding of categorical variables?
Interviewee: So we did perform some feature scaling and normalization and there were a few categorical variables such as what grade they were, how much money they got, or from what location that were. These are a few of the categorical variables which we converted into numerical 1 using label encoding.
Interviewer: Okay. So you performed feature scaling and normalization, and you used label encoding to convert categorical variables into numerical values. Can you elaborate on what specific scaling and normalization techniques you used? For example, did you use Standard Scaler or Min-Max Scaler?
Interviewee: So we use the standard scalar because we while doing the evaluation we observed that the data set was normal in nature. That's why you use the standard scalar.
Interviewer: Okay. So you used the Standard Scaler because you observed that the dataset was normally distributed. Can you tell me more about how you handled the data collection process in your project? For example, did you use any web scraping techniques or APIs to collect the data?
Interviewee: So the data was provided to us by the HR department of our company. So they had the historical data of the of how the employees had attracted. So they provided to us and based on that we build the model.
Interviewer: Okay. So the data was provided to you by the HR department, and you built the model based on that historical data. Can you tell me more about the data models you used to store and manage the data in your project? For example, did you use any specific databases such as MongoDB, Cassandra, or MySQL?
Interviewee: No, we didn't use any such databases to store the data set. We already trained the model and then we were not storing data set because of some privacy issues.
Interviewer: Okay. So you didn't use any databases to store the dataset due to privacy issues. Can you tell me more about the API concoctions you used in your project? For example, did you use any specific APIs to fetch or send data?
Interviewee: So this application was built on Python, so in order to create the back end API, we use the Flask Python framework to create those various endpoints to which requests could be made. In order to make those requests, we use the request library which is also there in Python.
Interviewer: Okay. So you used the Flask Python framework to create the backend API and the request library to make requests. Can you elaborate on how you handled the API endpoints? For example, did you use any specific routing or endpoint design patterns?
Interviewee: So we built the API using the Restful standards.
Interviewer: Okay. So you built the API using RESTful standards. Can you tell me more about how you handled the API's data serialization and deserialization? For example, did you use any specific libraries such as JSON or Pickle to serialize and deserialize the data?
Interviewee: So we handled everything as Jason objects. So whatever was being received by us and sent to us, we handle that as a decision object.
Interviewer: Okay. So you used JSON objects to handle data serialization and deserialization. Can you tell me more about how you handled the API's security and authentication? For example, did you use any specific libraries or frameworks such as OAuth or JWT to handle authentication and authorization?
Interviewee: No, we did not do any such mechanism any such frameworks to the authentication authorization, because the system was hosted on our own server and there the firewall team had already ensured that the request could only be received from a very specific system.
Interviewer: Okay. So you didn't implement any specific authentication or authorization mechanisms, as the system was hosted on your own server and the firewall team had already ensured that the requests could only be received from a specific system. Can you tell me more about your experience with Cloud platforms and Container orchestration? Have you worked with any specific Cloud providers such as AWS, Azure, or Google Cloud, or container orchestration tools such as Docker or Kubernetes?
Interviewee: So with respect to the cloud platforms, I have some experience with Azure where I have your utilized services such as Azure opening. Then I have used Azure speed service and the another one which I've used is Document intelligence. As for the containerization tools, I have experience with docker but limited experience in Kubernetes.
Interviewer: Okay. So you have experience with Azure and have used services such as Azure Open, Azure Speed, and Document Intelligence. You also have experience with Docker, but limited experience with Kubernetes. Can you tell me more about your experience with DevSecOps and how you have implemented security practices in your projects?
Interviewee: Sorry, I won't be able to answer that at the moment.
Interviewer: That's okay. We can move on to the next topic.
Interviewee: Thank you.
Interviewer: You're welcome, Jobin. That concludes our interview. Someone will be in touch with you regarding the outcome. Thank you again for your time and sharing your experiences with me today.
